apiVersion: ml.oneblock.ai/v1
kind: ModelTemplate
metadata:
  name: google-gemma-2b-model
spec:
  description: "This is a model template for the Gemma-2B model from Google"
---
apiVersion: ml.oneblock.ai/v1
kind: ModelTemplateVersion
metadata:
  name: google-gemma-2b-model
spec:
  templateName: google-gemma-2b-model
  # modelID is the ID that refers to the model in the OpenAI API.
  modelID: "google/gemma-2b"
  hfModelID: "google/gemma-2b"
  engineConfig:
    type: VLLMEngine
    maxTotalTokens: 2048
    # specify custom vLLM kw_args https://github.com/vllm-project/vllm/blob/main/vllm/engine/arg_utils.py
    vLLMArgs: |
      trust_remote_code: true
      max_num_batched_tokens: 2048
      max_num_seq: 16
      dtype: half
  deploymentConfig:
    replicas: 1
    maxReplicas: 2
    maxConcurrentQueries: 64
  scalingConfig:
    # the GPUs per worker is default to 1, if you want to using multiple GPUs just set numWorkers to be the number of GPUs you want to use.
    numWorkers: 1
    numCPUsPerWorker: 3
