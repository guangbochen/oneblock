---
apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  annotations:
    {}
  name: modeltemplateversions.ml.oneblock.ai
spec:
  group: ml.oneblock.ai
  names:
    kind: ModelTemplateVersion
    listKind: ModelTemplateVersionList
    plural: modeltemplateversions
    shortNames:
    - mtv
    - mtvs
    singular: modeltemplateversion
  scope: Namespaced
  versions:
  - additionalPrinterColumns:
    - jsonPath: .metadata.creationTimestamp
      name: AGE
      type: date
    name: v1
    schema:
      openAPIV3Schema:
        description: ModelTemplateVersion is the Schema for the LLM model
        properties:
          apiVersion:
            description: 'APIVersion defines the versioned schema of this representation
              of an object. Servers should convert recognized schemas to the latest
              internal value, and may reject unrecognized values. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources'
            type: string
          kind:
            description: 'Kind is a string value representing the REST resource this
              object represents. Servers may infer this from the endpoint the client
              submits requests to. Cannot be updated. In CamelCase. More info: https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds'
            type: string
          metadata:
            type: object
          spec:
            properties:
              deploymentConfig:
                description: DeploymentConfig specifies how to auto-scale the model
                  and what specific options you may need for your Ray Actors during
                  deployments
                properties:
                  maxConcurrentQueries:
                    format: int32
                    type: integer
                  maxReplicas:
                    default: 2
                    format: int32
                    type: integer
                  minReplicas:
                    default: 1
                    format: int32
                    type: integer
                  replicas:
                    default: 1
                    description: initial replicas
                    format: int32
                    type: integer
                  targetNumOngoingRequests:
                    description: Auto scale up/down the number of replicas if the
                      average number of ongoing requests is above/below this value.
                      Automatically set this to 40% of the maxConcurrentQueries if
                      not specified.
                    format: int32
                    type: integer
                required:
                - maxConcurrentQueries
                - maxReplicas
                - minReplicas
                - replicas
                type: object
              description:
                type: string
              engineConfig:
                description: EngineConfig specifies the model ID, inference engine,
                  and what parameters to use when generating tokens with an LLM.
                properties:
                  generation:
                    properties:
                      promptFormat:
                        properties:
                          addSystemTagsEvenIfMessageIsEmpty:
                            description: Whether to include the system tags even if
                              the user message is empty.
                            type: boolean
                          assistant:
                            description: Past assistant message. Used in chat completions
                              API.
                            type: string
                          defaultSystemMessage:
                            description: Default system message.
                            type: string
                          stripWhitespace:
                            default: true
                            description: Whether to automatically strip whitespace
                              from left and right of user supplied messages for chat
                              completions
                            type: boolean
                          system:
                            description: 'The format of the prompt. The following
                              fields are available: System message. Will default to
                              empty'
                            type: string
                          systemInUser:
                            description: Whether the system prompt is inside the user
                              prompt. If true, the user field should include '{system}'
                            type: boolean
                          trailingAssistant:
                            description: New assistant message. After this point,
                              model will generate tokens.
                            type: string
                          user:
                            description: User message
                            type: string
                        type: object
                      stoppingSequences:
                        items:
                          type: string
                        type: array
                    type: object
                  maxTotalTokens:
                    format: int32
                    type: integer
                  type:
                    default: VLLMEngine
                    type: string
                  vLLMArgs:
                    description: 'More details about engine config can be referred
                      to: vLLM: https://github.com/vllm-project/vllm/blob/main/vllm/config.py'
                    type: string
                required:
                - maxTotalTokens
                type: object
              hfModelID:
                description: HFModelID is the Hugging Face model ID. If not specified,
                  defaults to modelID
                type: string
              mirrorConfig:
                description: MirrorConfig helps to add a private model, you can either
                  choose to use an S3 or GCS mirror.
                type: string
              modelID:
                description: ModelID is the ID that refers to the model in the OpenAI
                  API.
                type: string
              scalingConfig:
                description: ScalingConfig specifies what resources should be used
                  to serve the model. Note that the scaling_config applies to each
                  model replica, and not the entire model deployment (in other words,
                  each replica will have $num_workers workers.
                properties:
                  numCPUsPerWorker:
                    description: Number of CPUs to be allocated per worker.
                    format: int32
                    type: integer
                  numWorkers:
                    description: Number of workers (i.e. Ray Actors) for each replica
                      of the model. This controls the tensor parallelism for the model.
                    format: int32
                    type: integer
                  placementStrategy:
                    default: STRICT_PACK
                    type: string
                  resourcesPerWorker:
                    additionalProperties:
                      type: string
                    description: 'You can use custom resources to specify the instance
                      type/accelerator type to use for the model. e.g., accelerator_type_a10:
                      0.01'
                    type: object
                required:
                - numCPUsPerWorker
                - numWorkers
                - placementStrategy
                type: object
              templateName:
                type: string
            required:
            - deploymentConfig
            - engineConfig
            - modelID
            - scalingConfig
            - templateName
            type: object
          status:
            properties:
              conditions:
                description: Conditions is an array of current conditions
                items:
                  properties:
                    lastTransitionTime:
                      description: Last time the condition transitioned from one status
                        to another.
                      type: string
                    lastUpdateTime:
                      description: The last time this condition was updated.
                      type: string
                    message:
                      description: Human-readable message indicating details about
                        last transition
                      type: string
                    reason:
                      description: The reason for the condition's last transition.
                      type: string
                    status:
                      description: Status of the condition, one of True, False, Unknown.
                      type: string
                    type:
                      description: Type of the condition.
                      type: string
                  required:
                  - status
                  - type
                  type: object
                type: array
              generatedModelConfig:
                type: string
              version:
                type: integer
            required:
            - version
            type: object
        type: object
    served: true
    storage: true
    subresources:
      status: {}
